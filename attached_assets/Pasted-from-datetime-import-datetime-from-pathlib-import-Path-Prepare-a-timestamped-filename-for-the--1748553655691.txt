from datetime import datetime
from pathlib import Path

# Prepare a timestamped filename for the WhisperRecorder upgrade
timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
filename = f"WhisperRecorder_Enhanced_{timestamp}.tsx"

# Output path for the file (will be provided to user)
output_path = Path("/mnt/data") / filename

# Core contents of the upgraded WhisperRecorder.tsx
enhanced_whisper_recorder_code = '''\
import React, { useState, useRef } from 'react';
import { WhisperRecorderProps } from './types';

export default function WhisperRecorder({ onTranscription, onResponse }: WhisperRecorderProps) {
  const [recording, setRecording] = useState(false);
  const [processing, setProcessing] = useState(false);
  const [transcription, setTranscription] = useState('');
  const [audioUrl, setAudioUrl] = useState('');
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunks: BlobPart[] = [];

  const startRecording = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const mediaRecorder = new MediaRecorder(stream);
    mediaRecorderRef.current = mediaRecorder;
    setRecording(true);
    chunks.length = 0;

    mediaRecorder.ondataavailable = (e) => {
      if (e.data.size > 0) chunks.push(e.data);
    };

    mediaRecorder.onstop = async () => {
      const blob = new Blob(chunks, { type: 'audio/webm' });
      const audioUrl = URL.createObjectURL(blob);
      setAudioUrl(audioUrl);
      setProcessing(true);

      const formData = new FormData();
      formData.append('audio', blob, 'recording.webm');

      try {
        const res = await fetch('/api/whisper', { method: 'POST', body: formData });
        const data = await res.json();

        if (data.text) {
          setTranscription(data.text);
          onTranscription?.(data.text); // Pass raw transcript to parent
        }
      } catch (err) {
        console.error('Transcription failed:', err);
      } finally {
        setProcessing(false);
      }
    };

    mediaRecorder.start();
  };

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    setRecording(false);
  };

  const sendToBot = async () => {
    if (!transcription) return;

    const res = await fetch('/api/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message: transcription })
    });
    const data = await res.json();
    onResponse?.(data);
    setTranscription('');
  };

  return (
    <div className="p-4 bg-gray-900 rounded-xl border border-gray-700 text-white">
      <div className="flex items-center gap-4">
        <button
          onClick={recording ? stopRecording : startRecording}
          disabled={processing}
          className={`px-6 py-3 rounded-lg font-medium transition-all ${
            processing
              ? 'bg-gray-600 cursor-not-allowed'
              : recording
              ? 'bg-red-600 hover:bg-red-700 animate-pulse'
              : 'bg-emerald-600 hover:bg-emerald-700'
          }`}
        >
          {processing ? 'üîÑ Processing...' : recording ? '‚èπÔ∏è Stop Recording' : 'üé§ Start Whisper Recording'}
        </button>
        {audioUrl && (
          <audio controls src={audioUrl} className="ml-4 max-w-xs" />
        )}
      </div>

      {transcription && (
        <div className="mt-4">
          <p className="text-sm text-gray-300 mb-2">üìù Transcription:</p>
          <div className="bg-gray-800 p-3 rounded-lg border border-gray-600 mb-3">{transcription}</div>
          <button
            onClick={sendToBot}
            className="bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded-lg"
          >
            Send to Lily
          </button>
        </div>
      )}
    </div>
  );
}
'''

# Save to file
output_path.write_text(enhanced_whisper_recorder_code)
output_path
